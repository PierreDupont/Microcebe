---
title: "Microcebus Capture-Recapture : a simulation study"
author: "Pierre Dupont"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Marmot Dispersal_simulation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
 
    
```{r child = "C:/Users/pidu/OneDrive - Norwegian University of Life Sciences/PROJECTS/demo-rmd-snow-main/snow.Rmd"}
``` 

This vignette demonstrates how to simulate a Microcebus-like capture-recapture dataset and analyze it using a custom capture-recapture model in NIMBLE (de Valpine et al., 2017).


## Load Libraries 

```{r packages, message=FALSE, warning=FALSE}
library(nimble)
library(basicMCMCplots)
library(coda)
```



## Simulate Data 

Here, we simulate a capture-recapture dataset based on the life-history and monitoring of Mandena's Microcebuses. We start by setting the simulation parameter values.

To simulate the population dynamics, we need to set up the number of individuals initially present (N0), as well as the demographic parameters.



### Set simulation characteristics
```{r sim parms1}
N0 <- 50                                           ## Initial population size       
n.years <- 10                                       ## Number of years simulated
season <- rep(c(1,1,1,1,1,1,1,1,2,2,2,2), n.years) ## Wet/dry seasons index
phi0 <- c(0.98,0.87)                                ## Time- and season-specific survival
beta <- c(-0.02,-0.01)
r <- 0.08                                          ## Reproduction probability
litterSize <- c(0.5,0.35,0.15)                     ## Vector of litter size probabilities
```


We also need to set the parameters for the sampling sessions (% of months sampled and mean duration of each sampling session)
```{r sim parms2}
meanDuration <- 4 
lambdaDet <- 0.45
propSession <- 0.46
```



### Generate CMR dataset 
Now, we can start simulating the CMR dataset and initialize simulation objects.
```{r pop sim1}
POP <- list()                                       ## List of population composition 
POP[[1]] <- rep(1, N0)                              ## Initial population composition
N <- vector()                                       ## List of population size
N[1] <- N0                                          ## Initial population size
```

Then, we simulate individual- and time-specific survival, recruitment, and litter size.
From that we derive monthly population sizes.
```{r pop sim2}
n.months <- 12*n.years
phi <- NULL 
start.int <- end.int <- NULL 
for(t in 2:n.months){
  phi[t-1] <- 1/(1+exp(-(logit(phi0[season[t]]) + beta[season[t]] * t)))
  Z <- B <- rep(0,length(POP[[t-1]]))        
  for(i in 1:length(POP[[t-1]])){       
    if(POP[[t-1]][i] == 1){         ## Sample states only if individual is alive
      Z[i] <- rbinom(1, 1, phi[t-1])## Sample individual survival
      repro <- rbinom(1, 1, r*Z[i]) ## Sample individual repro (only if individual survived)
      if(repro==1){B[i] <- sample( x = 1:3,
                                   size = 1,
                                   prob = litterSize)}## Sample individual litter size
    }#if
  }#i
  if(sum(B[]) > 0){Z <- c(Z, rep(1,sum(B[])))}       ## Add new recruits to the population vector
  N[t] <- sum(Z)                                     ## New population size
  POP[[t]] <- Z                                      ## New population composition
  if(length(POP[[t]]) > 200000)stop("pop size waayyyyyy too big...something is wrong!!!") 
}#t

## Plot of the population trajectory
plot(1:n.months, N, type = "l", axes = F,
     ylim = c(0, max(N)), lwd = 2,
     ylab = "Population size", xlab = "years")
axis(side = 1, at = (0:n.years)*12, labels = 0:n.years, xlab = "years")
axis(side = 2)
```

Here, we re-organize individual life-histories in a matrix.
```{r pop sim3}
z <- matrix(0, length(POP[[n.months]]), n.months)
for (t in 1:n.months){
  z[1:length(POP[[t]]), t] <- POP[[t]]
}#t
```

Then, we sample in which months the trapping sessions occured and how long each one lasts.
(First and last sessions must be sampling sessions for the model to make sense)
```{r pop sim4}
sessionIndex <- c( 1,
                   sample( x = 2:(n.months-1),
                           size = round(propSession*(n.months-2))),
                   n.months)
sessionIndex <- sessionIndex[order(sessionIndex)]
n.sessions <- length(sessionIndex)
```

Before sampling individual observations for each session.
```{r pop sim5}
sessionDuration <- rpois(n = n.sessions, lambda = meanDuration)
p <- 1 - exp(-lambdaDet * sessionDuration)

y <- matrix(0, dim(z)[1], n.sessions)
for(i in 1:dim(z)[1]){
  for (t in 1:n.sessions){
    y[i,t] <- rbinom(size = 1, n = 1, prob = p[t] * z[i,t])
  }#t
}#i
```


To match real-life CMR datasets, we need to filter out individuals that were never captured, as well as individuals that were detected for the first time on the last sampling session.
```{r pop sim6}
## Keep only detected individuals
detected <- apply(y, 1, function(x)any(x == 1))
y.detected <- y[detected, ]

## Extract the first detection occasion per individual
f <- apply(y.detected, 1, function(x)min(which(x == 1)))

## Remove individuals detected for the first time on the last session
y.detected <- y.detected[which(f != dim(y.detected)[2]), ]
f <- f[which(f != dim(y.detected)[2])]
```


To fit a model with both unequal time intervals between sampling sessions and sampling sessions that vary in duration, we have to identify which months correspongd to the start of each sampling session and the month that correspond to the end of the interval between two sampling sessions.
```{r pop sim7}
start.int <- end.int <- dt1 <- dt2 <- NULL
for(t in 1:(length(sessionIndex)-1)){
  start.int[t] <- sessionIndex[t]
  end.int[t] <- sessionIndex[t+1]-1
  # dt1[t] <- sum(season[start.int[t]:end.int[t]] == 1)
  # dt2[t] <- sum(season[start.int[t]:end.int[t]] == 2)
}#t
```

## -----------------------------------------------------------------------------

## Fit the model with NIMBLE

### Define NIMBLE Model Structure 

Here, we define the `NIMBLE` model.
```{r NIMBLE model}
modelCode <- nimbleCode({
  ##---------------------
  ## DEMOGRAPHIC PROCESS 
  phi0[1] ~ dunif(0,1)
  phi0[2] ~ dunif(0,1)
  logit.phi0[1] <- logit(phi0[1])
  logit.phi0[2] <- logit(phi0[2])
  beta[1] ~ dnorm(0,0.01)
  beta[2] ~ dnorm(0,0.01)
  for(m in 1:n.months){
    # PHI[m] <- phi0[season[m]] + beta[season[m]] * m
    logit(PHI[m]) <- logit.phi0[season[m]] + beta[season[m]] * m
  }# months
  
  for(t in 1:n.intervals){
    phi[t] <- prod(PHI[start.int[t]:end.int[t]])
    # phi[t] <- getPhi(phiVec = PHI[start.int[t]:end.int[t]])
    # phi[t] <- pow(phi0[1], dt1[t]) * pow(phi0[2], dt2[t]) # Session-specific survival probabilities
  }# time
  
  for(i in 1:n.individuals){
    z[i,f[i]] ~ dbern(1)  
    for(t in f[i]:n.intervals){
      z[i,t+1] ~ dbern(z[i,t] * phi[t])  
    }#t
  }#i
  
  ##------------------
  ## DETECTION PROCESS
  ## Detection Hazard rate
  lambda ~ dgamma(0.01,0.01)                   
  for(t in 1:n.sessions){
    ## Allows for unequal sampling sessions (sessionDuration[t])
    p[t] <- 1-exp(-lambda * sessionDuration[t]) 
  }# session
  
  for(i in 1:n.individuals){
    for(t in (f[i]+1):n.sessions){
      y[i,t] ~ dbern(p[t] * z[i,t])
    }#t
  }#i
  
  ##----------------------------------------------------------------------------
})

```


### Format the data for NIMBLE 

Then, we organize the simulated data in a format useable by NIMBLE; i.e. we create objects `constants`, `data`, and `inits` for later use in the function `nimbleModel`. 
```{r NIMBLE data}
nimData <- list( y = y.detected,
                 sessionDuration = sessionDuration )

nimConstants <- list( n.individuals = dim(y.detected)[1],
                      n.months = n.months,
                      n.intervals = dim(y.detected)[2]-1,
                      n.sessions = dim(y.detected)[2],
                      season = season,
                      f = f,
                      start.int = start.int,
                      end.int = end.int)


l <- apply(nimData$y, 1, function(x)max(which(x == 1)))
z.init <- matrix(data =  NA,
                 nrow = nrow(nimData$y),
                 ncol = ncol(nimData$y))
for(i in 1:dim(z.init)[1]){
  z.init[i,f[i]:l[i]] <- 1
  if(l[i]<dim(z.init)[2]){
    z.init[i,(l[i]+1):(dim(z.init)[2])] <- 0
  }
}#i
nimInits <- list( z = z.init,
                  phi0 = c(0.85,0.85),
                  beta = c(0,0),
                  lambda = 0.5)
```


### Create a NIMBLE model object 

Now, we can create the `nimble` model object, using the model structure
defined in `code`, and the constants, data, and initial values.
```{r NIMBLE Rmodel}
Rmodel <- nimbleModel( code = modelCode,
                       constants = nimConstants,
                       data = nimData,
                       inits = nimInits,
                       calculate = F)
Rmodel$calculate()
```


### Configure and Build MCMC objects 

We configure an MCMC algorithm to the `Rmodel` model object.

We assign MCMC monitors to $\phi$, $\gamma$, $lambda$, and $\psi$.

```{r NIMBLE config, message=FALSE}
conf <- configureMCMC(Rmodel, monitors = c("phi0", "beta", "lambda"), print = FALSE)
Rmcmc <- buildMCMC(conf)
```


### Compile and Run MCMC 

Finally, we compile both the model and MCMC objects and
execute the compiled MCMC for 5 000 iterations and 3 chains.

```{r NIMBLE compile}
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
MCMC_runtime <- system.time(
  samples <- runMCMC( Cmcmc,
                      niter = 5000,
                      nburnin = 1000,
                      nchains = 3,
                      samplesAsCodaMCMC = T))
```

## Results 

First, we can look at a summary of the posterior distributions for each parameter:
```{r }
summary(samples)
```

We can then examine traceplots and posterior distribution densities:
```{r, width=8, height=10}
#plot(samples)
basicMCMCplots::chainsPlot(samples)
```

We can also extract the MCMC runtime (`r round(MCMC_runtime[3] / 60, 1)` minutes in this case): 
```{r }
round(MCMC_runtime[3] / 60, 1)
```

And check the posterior effective sample size (ESS) resulting from our 15 000 posterior samples for the parameters we tracked ( $\phi_0$, $\beta$ and $\lambda$):  
```{r }
round(effectiveSize(samples),2) 
```

Finally, we can calculate the MCMC efficiency for each parameter; this corresponds to the rate of generating effectively independent posterior samples, per second of MCMC runtime:
```{r }
 round(effectiveSize(samples)/MCMC_runtime[3],2)  
```


